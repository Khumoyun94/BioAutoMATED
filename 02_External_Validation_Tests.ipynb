{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides code to test all models with validation datasets (either held out test sets or external validation datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import statements \n",
    "import sys\n",
    "sys.path.insert(1, './main_classes/')\n",
    "\n",
    "from transfer_learning_helpers import read_in_format_data_and_pred\n",
    "import scipy.stats as sp\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBS - binary classification example\n",
    "# Test set is test set from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: All sequence characters are in alphabet\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "WARNING:tensorflow:From /anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda2/envs/automl_py37/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Number of labeled binary positives with cutoff of 0.12491: 13836\n",
      "Number of total test set: 27654\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.72785  with a p-val of  0.0\n",
      "Pearson R:  0.85314  with a p-val of  0.0\n",
      "Spearman R:  0.8184  with a p-val of  0.0\n",
      "auROC:  0.91454\n",
      "MCC:  0.65858\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'hollerer_rbs_test.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'out'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'nucleic_acid'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/rbs/models/'\n",
    "output_folder = './exemplars/rbs/outputs/'\n",
    "model_type = 'deepswarm'\n",
    "task = 'binary_classification'\n",
    "class_of_interest = 1 # 1 for binary classification typically!\n",
    "\n",
    "# can provide cut-off for binarizing; for instance, here we would supply the SAME cut-off as \n",
    "# the one used in the original TRAIN set\n",
    "train_set = pd.read_csv(data_folder + 'hollerer_rbs_train.csv')\n",
    "cutoff = np.median(train_set[target_col].values)\n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff, cutoff_pred = cutoff);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RBS - regression model example\n",
    "# Test set is test set from the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: All sequence characters are in alphabet\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "Number of labeled binary positives with cutoff of 0.12491: 13836\n",
      "Number of total test set: 27654\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.86654  with a p-val of  0.0\n",
      "Pearson R:  0.93088  with a p-val of  0.0\n",
      "Spearman R:  0.87941  with a p-val of  0.0\n",
      "auROC:  0.93908\n",
      "MCC:  0.72465\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'hollerer_rbs_test.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'out'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'nucleic_acid'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/rbs/models/'\n",
    "output_folder = './exemplars/rbs/outputs/'\n",
    "model_type = 'autokeras'\n",
    "task = 'regression'\n",
    "class_of_interest = 0 # 0 for regression\n",
    "\n",
    "# can provide cut-off for binarizing; for instance, here we would supply the SAME cut-off as \n",
    "# the one used in the original TRAIN set\n",
    "train_set = pd.read_csv(data_folder + 'hollerer_rbs_train.csv')\n",
    "cutoff = np.median(train_set[target_col].values)\n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff, cutoff_pred = cutoff);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptides - binary classification\n",
    "# External validation with held-out classification test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unknown letter(s) \"X, J\" found in sequence\n",
      "Example of bad letter X: JJHKPQAKSYXPYRILDYJJ\n",
      "Example of bad letter J: JJHKPQAKSYLAYRILDYJJ\n",
      "Replacing J with substitution : L, I\n",
      "Setting all substitutions to 1 in one-hot encoded representation...\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "WARNING:tensorflow:From /anaconda2/envs/automl_py37/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Number of labeled binary positives with cutoff of 1: 207\n",
      "Number of total test set: 471\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.31839  with a p-val of  0.0\n",
      "Pearson R:  0.56426  with a p-val of  0.0\n",
      "Spearman R:  0.66286  with a p-val of  0.0\n",
      "auROC:  0.86909\n",
      "MCC:  0.54779\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'classification_test_peptides.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'target'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'protein'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/peptides/models/'\n",
    "output_folder = './exemplars/peptides/outputs/'\n",
    "model_type = 'deepswarm'\n",
    "task = 'binary_classification'\n",
    "class_of_interest = 1 # 1 for binary classification typically\n",
    "\n",
    "# 1 chosen as cut-off because in the supplement they said: \n",
    "# \"In the regression datasets, the R2-to-R3 enrichment was used as a label\" \n",
    "cutoff_true = 1\n",
    "cutoff_pred = 0.5 # use 0.5 as predicted ys cut-off, since they will max out at 1\n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff_true, cutoff_pred = cutoff_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peptides - regression model example\n",
    "# External validation with held-out classification test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unknown letter(s) \"X, J\" found in sequence\n",
      "Example of bad letter X: JJHKPQAKSYXPYRILDYJJ\n",
      "Example of bad letter J: JJHKPQAKSYLAYRILDYJJ\n",
      "Replacing J with substitution : L, I\n",
      "Setting all substitutions to 1 in one-hot encoded representation...\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "Number of labeled binary positives with cutoff of 1: 207\n",
      "Number of total test set: 471\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.43467  with a p-val of  0.0\n",
      "Pearson R:  0.6593  with a p-val of  0.0\n",
      "Spearman R:  0.67809  with a p-val of  0.0\n",
      "auROC:  0.86764\n",
      "MCC:  0.52267\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'classification_test_peptides.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'target'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'protein'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/peptides/models/'\n",
    "output_folder = './exemplars/peptides/outputs/'\n",
    "model_type = 'tpot'\n",
    "task = 'regression'\n",
    "class_of_interest = 0 # 0 for regression\n",
    "\n",
    "# 1 chosen as cut-off because in the supplement they said: \n",
    "# \"In the regression datasets, the R2-to-R3 enrichment was used as a label\" \n",
    "cutoff_true = 1\n",
    "cutoff_pred = 1 \n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff_true, cutoff_pred = cutoff_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP proteins - regression model example with DeepSwarm\n",
    "# External validation with held-out regression test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: All sequence characters are in alphabet\n",
      "Padding all sequences to a length of 749\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "Number of labeled binary positives with cutoff of 1: 3580\n",
      "Number of total test set: 16517\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.87665  with a p-val of  0.0\n",
      "Pearson R:  0.9363  with a p-val of  0.0\n",
      "Spearman R:  0.93038  with a p-val of  0.0\n",
      "auROC:  0.95711\n",
      "MCC:  0.23709\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'flip_protein_test.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'sequence'\n",
    "target_col = 'target'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'protein'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/flip_longer_protein/models/'\n",
    "output_folder = './exemplars/flip_longer_protein/outputs/'\n",
    "model_type = 'autokeras'\n",
    "task = 'regression'\n",
    "class_of_interest = 0 # 0 for regression\n",
    "\n",
    "cutoff_true = 1\n",
    "cutoff_pred = 1 \n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff_true, cutoff_pred = cutoff_pred);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toeholds - regression example\n",
    "# Test set is additional toeholds from Valeri, Collins, Ramesh et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: All sequence characters are in alphabet\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "Number of labeled binary positives with cutoff of 0.5: 42\n",
      "Number of total test set: 168\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.10803  with a p-val of  1e-05\n",
      "Pearson R:  0.32868  with a p-val of  1e-05\n",
      "Spearman R:  0.33702  with a p-val of  1e-05\n",
      "auROC:  0.72468\n",
      "MCC:  0.28776\n"
     ]
    }
   ],
   "source": [
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'green_sequences_toehold_test_set.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'target'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'nucleic_acid'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/toeholds/models/'\n",
    "output_folder = './exemplars/toeholds/outputs/'\n",
    "model_type = 'autokeras'\n",
    "task = 'regression'\n",
    "class_of_interest = 0 # 0 for regression\n",
    "\n",
    "cutoff_true = 0.5\n",
    "cutoff_pred = 0.5\n",
    "\n",
    "read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, cutoff_true = cutoff_true, cutoff_pred = cutoff_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confirmed: All sequence characters are in alphabet\n",
      "Confirmed: No need to pad or truncate, all sequences same length\n",
      "Confirmed: No data augmentation requested\n",
      "Confirmed: Scrambled control generated.\n",
      "Number of total test set: 24\n",
      "\n",
      "Computing statistics now...\n",
      "R2:  0.097  with a p-val of  0.13848\n",
      "Pearson R:  0.31145  with a p-val of  0.13848\n",
      "Spearman R:  0.30696  with a p-val of  0.14457\n"
     ]
    }
   ],
   "source": [
    "# fix dataset so it is amenable to previously trained model\n",
    "pardee = pd.read_csv('./clean_data/clean/pardee_sequences_toehold_test_set.csv')\n",
    "pardee['seq'] = [s[18:77] for s in pardee['seq']] # based on Pardee et al.\n",
    "pardee['rank'] = [24 - x for x in pardee['rank']] # reverse\n",
    "pardee.to_csv('./clean_data/clean/clean_pardee_sequences_toehold_test_set.csv', index = False)\n",
    "\n",
    "# Read in data file\n",
    "data_folder = './clean_data/clean/'\n",
    "data_file = 'clean_pardee_sequences_toehold_test_set.csv'\n",
    "\n",
    "# Give inputs for data generation\n",
    "input_col= 'seq'\n",
    "target_col = 'rank'\n",
    "pad_seqs = 'max'\n",
    "augment_data = 'none'\n",
    "sequence_type = 'nucleic_acid'\n",
    "\n",
    "# Give inputs for paths\n",
    "model_folder = './exemplars/toeholds/models/'\n",
    "output_folder = './exemplars/toeholds/outputs/'\n",
    "model_type = 'autokeras'\n",
    "task = 'regression'\n",
    "class_of_interest = 0 # 0 for regression\n",
    "\n",
    "# have to do this one manually since we only have rank data for these toeholds\n",
    "y_pred, y_true = read_in_format_data_and_pred(task, data_folder, data_file, input_col, target_col, pad_seqs, augment_data, sequence_type, model_type, model_folder, output_folder, class_of_interest = class_of_interest, stats = False)\n",
    "\n",
    "print('Number of total test set: ' + str(len(y_true)))\n",
    "print('\\nComputing statistics now...')\n",
    "slope, intercept, r_val, p_val, std_error = sp.linregress(y_true, y_pred)\n",
    "print('R2: ', np.round(r_val ** 2, 5), ' with a p-val of ', np.round(p_val, 5))\n",
    "pear = sp.pearsonr(y_true, y_pred)\n",
    "print('Pearson R: ', np.round(pear[0], 5) , ' with a p-val of ', np.round(pear[1], 5))\n",
    "spear = sp.spearmanr(y_true, y_pred)\n",
    "print('Spearman R: ', np.round(spear[0], 5) , ' with a p-val of ', np.round(spear[1], 5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "automl_py37",
   "language": "python",
   "name": "automl_py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
