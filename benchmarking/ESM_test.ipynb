{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get virtual environment installed for ESM, I did the following:\n",
    "\n",
    "`conda create --name esm python=3.7\n",
    "sudo apt-get install python-pip\n",
    "sudo apt update\n",
    "sudo apt install python3-pip\n",
    "sudo apt-get install libjpeg-dev\n",
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "pip install fair-esm\n",
    "pip install git+https://github.com/facebookresearch/esm.git  # bleeding edge, current repo main branch\n",
    "git clone https://github.com/facebookresearch/esm.git\n",
    "conda install -c anaconda ipykernel\n",
    "python -m ipykernel install --user --name=esm\n",
    "conda install -c conda-forge tqdm\n",
    "sudo pip3 install tqdm \n",
    "pip install matplotlib pandas seaborn scipy\n",
    "conda install scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import esm\n",
    "\n",
    "import scipy\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert benchmark peptide dataset to embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot handle Js in peptide data! replace with L for all J\n",
    "peptide = pd.read_csv('./data/JV_data/peptides.csv')\n",
    "outpath = \"./data/JV_data/peptides_for_embedding\"\n",
    "file = open(outpath + '.fasta', 'w')\n",
    "index = 0\n",
    "vals = []\n",
    "seqs = []\n",
    "for seq, on in zip(list(peptide['seq']), list(peptide['target'])):\n",
    "    seq = seq.replace(\"J\", \"L\")\n",
    "    file.write(\">\" + str(index) + '|' + str(index) + '|' + str(on) + \"\\n\" + seq + \"\\n\")\n",
    "    index = index + 1\n",
    "file.close() #do not forget to close it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert sequences to embeddings, run: \n",
    "\n",
    "`python scripts/extract.py esm2_t33_650M_UR50D examples/data/JV_data/peptides_for_embedding.fasta examples/data/JV_data/peptides_for_embedding --repr_layers 0 32 33 --include mean per_tok`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings and generate train/test splits for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTA_PATH = \"./data/JV_data/peptides_for_embedding.fasta\"\n",
    "EMB_PATH = \"./data/JV_data/peptides_for_embedding\"\n",
    "\n",
    "EMB_LAYER = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67769\n",
      "(67769, 1280)\n"
     ]
    }
   ],
   "source": [
    "ys = []\n",
    "Xs = []\n",
    "for header, _seq in esm.data.read_fasta(FASTA_PATH):\n",
    "    scaled_effect = header.split('|')[-1]\n",
    "    ys.append(float(scaled_effect))\n",
    "    fn = f'{EMB_PATH}/{header}.pt'\n",
    "    embs = torch.load(fn)\n",
    "    Xs.append(embs['mean_representations'][EMB_LAYER])\n",
    "Xs = torch.stack(Xs, dim=0).numpy()\n",
    "print(len(ys))\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54215, 1280), (13554, 1280), 54215, 13554)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 0.8\n",
    "Xs_train, Xs_test, ys_train, ys_test = train_test_split(Xs, ys, train_size=train_size, random_state=42)\n",
    "\n",
    "Xs_train.shape, Xs_test.shape, len(ys_train), len(ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train three types of scikit-learn models and evaluate cross-validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([0.20871258, 0.20620513, 0.21264458]), 'score_time': array([38.52070427, 40.65353727, 38.65091777]), 'test_r2': array([0.05416103, 0.15476717, 0.17504163]), 'train_r2': array([0.5480586 , 0.54198079, 0.49187272])}\n"
     ]
    }
   ],
   "source": [
    "_scoring = ['r2']\n",
    "_cv = 3\n",
    "\n",
    "results = cross_validate(estimator=KNeighborsRegressor(),\n",
    "                               X=Xs,\n",
    "                               y=ys,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([11234.61773443, 11404.13718867, 11250.20415258]), 'score_time': array([1.59572792, 1.58039427, 1.51511288]), 'test_r2': array([0.10818455, 0.12395164, 0.17530255]), 'train_r2': array([0.91410091, 0.91030729, 0.90278354])}\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(estimator=RandomForestRegressor(),\n",
    "                               X=Xs,\n",
    "                               y=ys,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_time': array([1836.60960579, 1839.91163206, 1846.5775888 ]), 'score_time': array([1196.26056409, 1200.58589315, 1137.9080894 ]), 'test_r2': array([0.0246183 , 0.0461565 , 0.05675271]), 'train_r2': array([0.21208438, 0.19719572, 0.12409563])}\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(estimator=SVR(),\n",
    "                               X=Xs,\n",
    "                               y=ys,\n",
    "                               cv=_cv,\n",
    "                               scoring=_scoring,\n",
    "                               return_train_score=True)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test external test set performance - compute embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cannot handle Js in peptide data! replace with L for all J\n",
    "peptide = pd.read_csv('./data/JV_data/TESTSET_peptides.csv')\n",
    "outpath = \"./data/JV_data/TESTSET_peptides_for_embedding\"\n",
    "file = open(outpath + '.fasta', 'w')\n",
    "index = 0\n",
    "vals = []\n",
    "seqs = []\n",
    "for seq, on in zip(list(peptide['seq']), list(peptide['target'])):\n",
    "    seq = seq.replace(\"J\", \"L\")\n",
    "    file.write(\">\" + str(index) + '|' + str(index) + '|' + str(on) + \"\\n\" + seq + \"\\n\")\n",
    "    index = index + 1\n",
    "file.close() #do not forget to close it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, run below to convert sequences to embeddings: \n",
    "    \n",
    "`python scripts/extract.py esm2_t33_650M_UR50D examples/data/JV_data/TESTSET_peptides_for_embedding.fasta examples/data/JV_data/TESTSET_peptides_for_embedding --repr_layers 0 32 33 --include mean per_tok`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load embeddings for external test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTFASTA_PATH = \"./data/JV_data/TESTSET_peptides_for_embedding.fasta\"\n",
    "TESTEMB_PATH = \"./data/JV_data/TESTSET_peptides_for_embedding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "471\n",
      "(471, 1280)\n"
     ]
    }
   ],
   "source": [
    "ys_test = []\n",
    "Xs_test = []\n",
    "for header, _seq in esm.data.read_fasta(TESTFASTA_PATH):\n",
    "    scaled_effect = header.split('|')[-1]\n",
    "    ys_test.append(float(scaled_effect))\n",
    "    fn = f'{TESTEMB_PATH}/{header}.pt'\n",
    "    embs = torch.load(fn)\n",
    "    Xs_test.append(embs['mean_representations'][EMB_LAYER])\n",
    "Xs_test = torch.stack(Xs_test, dim=0).numpy()\n",
    "print(len(ys_test))\n",
    "print(Xs_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((67769, 1280), (471, 1280), 67769, 471)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train.shape, Xs_test.shape, len(ys_train), len(ys_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test three scikit-learn models on external test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.664371808241041, pvalue=2.7514495971080336e-61)\n",
      "0.4107362125400169\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(Xs_train, ys_train)\n",
    "y_preds = knn.predict(Xs_test)\n",
    "print(f'{scipy.stats.spearmanr(ys_test, y_preds)}')\n",
    "slope, intercept, r_val, p_val, std_error = scipy.stats.linregress(ys_test, y_preds)\n",
    "print(f'{r_val ** 2}') # r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.8340329946971428, pvalue=3.225625228286665e-123)\n",
      "0.7304124943507356\n"
     ]
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(Xs_train, ys_train)\n",
    "y_preds = rfr.predict(Xs_test)\n",
    "print(f'{scipy.stats.spearmanr(ys_test, y_preds)}')\n",
    "slope, intercept, r_val, p_val, std_error = scipy.stats.linregress(ys_test, y_preds)\n",
    "print(f'{r_val ** 2}') # r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpearmanrResult(correlation=0.6259867349874955, pvalue=1.3094123401043502e-52)\n",
      "0.4910201495353209\n"
     ]
    }
   ],
   "source": [
    "svr = SVR()\n",
    "svr.fit(Xs_train, ys_train)\n",
    "y_preds = svr.predict(Xs_test)\n",
    "print(f'{scipy.stats.spearmanr(ys_test, y_preds)}')\n",
    "slope, intercept, r_val, p_val, std_error = scipy.stats.linregress(ys_test, y_preds)\n",
    "print(f'{r_val ** 2}') # r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
